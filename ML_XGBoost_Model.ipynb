{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oo62sIFT_Zs"
      },
      "source": [
        "## XGradientBoost Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWvt0tNqUZuV"
      },
      "source": [
        "### Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzAFBjoET8tn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from itertools import product\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from itertools import product\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5Nee89OUhKS"
      },
      "source": [
        "### Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BL9oWrtcUibf"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('https://drive.google.com/uc?id=1sbFAHLYmyOBhHZ8yHqct2yhViRRV9r3u')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "Xd-LVaElUjRY",
        "outputId": "9d1d1fe9-2e65-4693-e3c0-97a09c66ead4"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bp6nspIPUwyV"
      },
      "outputs": [],
      "source": [
        "df_XGB = df.drop(columns=['TimeStamp','WindSpeed_Bin'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "gjWcwHItUzQU",
        "outputId": "882a625a-42bf-49ad-a671-84f8a3c05c1e"
      },
      "outputs": [],
      "source": [
        "df_XGB.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bni2CuBVClL"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYZVIykZVE-h"
      },
      "outputs": [],
      "source": [
        "\n",
        "class XGBoostRegressorModel:\n",
        "    def __init__(self, params=None, num_boost_round=1000, early_stopping_rounds=10):\n",
        "        # num_boost_round: max number of boosting iterations, early stopping: stop if validation error doesn't improve this many rounds\n",
        "        self.params = {\n",
        "            'objective': 'reg:squarederror',\n",
        "            'eta': 0.05,               # learning_rate\n",
        "            'max_depth': 6,             # max tree depth\n",
        "            'subsample': 0.8,\n",
        "            'colsample_bytree': 0.8,\n",
        "            'seed': 42,\n",
        "            'verbosity': 0\n",
        "        }\n",
        "        if params:\n",
        "            self.params.update(params)  # allows to override defaults\n",
        "\n",
        "        self.num_boost_round = num_boost_round\n",
        "        self.early_stopping_rounds = early_stopping_rounds\n",
        "        self.bst = None  # the trained Booster\n",
        "\n",
        "    def _evaluate(self, y_true, y_pred):\n",
        "        eps = 1e-2\n",
        "        mask = y_true > eps\n",
        "\n",
        "        if np.sum(mask) == 0:\n",
        "            print(\"[Warning] No valid values after masking low y_true values.\")\n",
        "            return {}\n",
        "\n",
        "        y_true = y_true[mask]\n",
        "        y_pred = y_pred[mask]\n",
        "        pct = (y_pred - y_true) / y_true\n",
        "\n",
        "        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "        mean_y = np.mean(y_true)\n",
        "        rmsep_approx = (rmse /mean_y) * 100\n",
        "        r2 = r2_score(y_true, y_pred)\n",
        "        mae = mean_absolute_error(y_true, y_pred)\n",
        "        smape = np.mean(2.0 * np.abs(y_true - y_pred) / (np.abs(y_true) + np.abs(y_pred) + eps)) * 100\n",
        "\n",
        "        return {\n",
        "            'RMSE':  rmse,\n",
        "            'RMSEP_approx (%)': rmsep_approx,\n",
        "            'R2':    r2,\n",
        "            'MAE':   mae,\n",
        "            'SMAPE (%)': smape\n",
        "        }\n",
        "\n",
        "\n",
        "    def run(self, df, target_column='ActivePower_Mean'):\n",
        "\n",
        "        # 1. Split features/target\n",
        "        X = df.drop(columns=[target_column])\n",
        "        y = df[target_column].values\n",
        "\n",
        "        # 2. Train/val/test 70/15/15\n",
        "        X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "            X, y, test_size=0.30, random_state=42)\n",
        "        X_val, X_test, y_val, y_test = train_test_split(\n",
        "            X_temp, y_temp, test_size=0.50, random_state=42)\n",
        "\n",
        "        # 3. Build DMatrix objects, convert to DMatrix\n",
        "        dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "        dval   = xgb.DMatrix(X_val,   label=y_val)\n",
        "        dtest  = xgb.DMatrix(X_test,  label=y_test)\n",
        "\n",
        "        # 4. Train with early stopping on validation set, applies validation when validation RMSE plateaus\n",
        "        evallist = [(dtrain, 'train'), (dval, 'validation')]\n",
        "        self.bst = xgb.train(\n",
        "            self.params,\n",
        "            dtrain,\n",
        "            num_boost_round=self.num_boost_round,\n",
        "            evals=evallist,\n",
        "            early_stopping_rounds=self.early_stopping_rounds,\n",
        "            verbose_eval=False\n",
        "        )\n",
        "\n",
        "        # 5. Predict\n",
        "        y_train_pred = self.bst.predict(dtrain)\n",
        "        y_val_pred   = self.bst.predict(dval)\n",
        "        y_test_pred  = self.bst.predict(dtest)\n",
        "\n",
        "        # 6. Evaluate\n",
        "        train_metrics = self._evaluate(y_train, y_train_pred)\n",
        "        val_metrics   = self._evaluate(y_val,   y_val_pred)\n",
        "        test_metrics  = self._evaluate(y_test,  y_test_pred)\n",
        "\n",
        "        # 7. Report\n",
        "        print(\"Training Metrics:   \", train_metrics)\n",
        "        print(\"Validation Metrics: \", val_metrics)\n",
        "        print(\"Test Metrics:       \", test_metrics)\n",
        "\n",
        "        return {\n",
        "            'train': train_metrics,\n",
        "            'val':   val_metrics,\n",
        "            'test':  test_metrics\n",
        "        }\n",
        "\n",
        "    def grid_search(self, df, target_column: str = 'ActivePower_Mean', param_grid: dict | None = None, primary_metric: str = 'RMSE') -> tuple[dict, list]:\n",
        "\n",
        "      # 1) Prepare data\n",
        "      X = df.drop(columns=[target_column])\n",
        "      y = df[target_column].values\n",
        "\n",
        "      X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "          X, y, test_size=0.30, random_state=42\n",
        "      )\n",
        "      X_val, _, y_val, _ = train_test_split(\n",
        "          X_temp, y_temp, test_size=0.50, random_state=42\n",
        "      )\n",
        "\n",
        "      # 2) Convert to DMatrix\n",
        "      dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "      dval   = xgb.DMatrix(X_val,   label=y_val)\n",
        "\n",
        "      # 3) Prepare to collect results\n",
        "      all_results: list[dict] = []\n",
        "\n",
        "      # 4) Iterate over every combination of parameters\n",
        "      keys, values = zip(*param_grid.items())\n",
        "      for combo in product(*values):\n",
        "          # Build a dict for this combination\n",
        "          trial_params = dict(zip(keys, combo))\n",
        "\n",
        "          # 4a) Override just those in self.params\n",
        "          original_params = self.params.copy()\n",
        "          self.params.update(trial_params)\n",
        "\n",
        "          # 4b) Train\n",
        "          bst = xgb.train(\n",
        "              params=self.params,\n",
        "              dtrain=dtrain,\n",
        "              num_boost_round=self.num_boost_round,\n",
        "              evals=[(dtrain, 'train')],\n",
        "              early_stopping_rounds=self.early_stopping_rounds,\n",
        "              verbose_eval=False\n",
        "          )\n",
        "\n",
        "          # 4c) Predict on validation set\n",
        "          y_val_pred = bst.predict(dval)\n",
        "\n",
        "          # 4d) Evaluate metrics\n",
        "          metrics = self._evaluate(y_val, y_val_pred)\n",
        "\n",
        "          # Store trial result\n",
        "          all_results.append({\n",
        "              'params': trial_params.copy(),\n",
        "              'metrics': metrics\n",
        "          })\n",
        "\n",
        "          # Restore original params\n",
        "          self.params = original_params\n",
        "\n",
        "      # 5) Find best by primary_metric (lowest value)\n",
        "      best = min(all_results, key=lambda r: r['metrics'][primary_metric])\n",
        "\n",
        "      print(f\"Best params by {primary_metric}: {best['params']}\")\n",
        "      print(f\"{primary_metric} = {best['metrics'][primary_metric]:.4f}\")\n",
        "\n",
        "      return best, all_results\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "784cS9Xu5ZHw"
      },
      "source": [
        "### Application Small Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pn28Z_eB5YJP",
        "outputId": "175f51d5-df5f-4932-dc6e-e3b826588b68"
      },
      "outputs": [],
      "source": [
        "# 0) Sample 10% of data to test pipeline speed\n",
        "df_small = df_XGB.sample(frac=0.1, random_state=42)\n",
        "\n",
        "# 1) Use a minimal grid (one combo)\n",
        "param_grid = {\n",
        "    'eta':              [0.1],    # single value\n",
        "    'max_depth':        [3],      # single value\n",
        "    'subsample':        [0.8],    # single value\n",
        "    'colsample_bytree': [0.8],    # single value\n",
        "    'reg_alpha':        [0.0],\n",
        "    'reg_lambda':       [0.5]\n",
        "}\n",
        "\n",
        "# 2) Fewer boosting rounds and very aggressive early stopping\n",
        "xgb_model = XGBoostRegressorModel(\n",
        "    params={'verbosity': 0},\n",
        "    num_boost_round=50,            # only 50 trees\n",
        "    early_stopping_rounds=5        # stop after 5 rounds of no improvement\n",
        ")\n",
        "\n",
        "# 3) Run grid search (this will effectively train just once on the small subset)\n",
        "best, all_results = xgb_model.grid_search(\n",
        "    df_small,\n",
        "    target_column='ActivePower_Mean',\n",
        "    param_grid=param_grid,\n",
        "    primary_metric='RMSE'\n",
        ")\n",
        "\n",
        "# 4) Update and do a quick full run\n",
        "xgb_model.params.update(best['params'])\n",
        "final_results = xgb_model.run(df_small, target_column='ActivePower_Mean')\n",
        "\n",
        "print(\"Quick‚Äêtest results:\", final_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "byeC7CJb9A0L",
        "outputId": "b7dc6487-ce1b-47d3-ba46-0d8fba46472b"
      },
      "outputs": [],
      "source": [
        "# Grid Search Results\n",
        "\n",
        "rows = [\n",
        "    {**trial['params'], **trial['metrics']}\n",
        "    for trial in all_results\n",
        "]\n",
        "df_results = pd.DataFrame(rows)\n",
        "\n",
        "# 3) Sort by your primary metric and display\n",
        "df_results = df_results.sort_values('RMSE').reset_index(drop=True)\n",
        "df_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5BZaL0LYK32"
      },
      "source": [
        "### Application (entire dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1kWIsjPYKHT",
        "outputId": "dfaf3cad-e5ed-4ccf-9a92-b87ee15a35a9"
      },
      "outputs": [],
      "source": [
        "# Define grid\n",
        "param_grid = {\n",
        "    'eta':              [0.05, 0.1, 0.2],\n",
        "    'max_depth':        [4, 5, 6],\n",
        "    'subsample':        [0.7, 0.8, 0.9],\n",
        "    'colsample_bytree': [0.7, 0.8, 0.9],\n",
        "    'reg_alpha':        [0.000001,0.0001,1.0],\n",
        "    'reg_lambda':       [0.5,10,20]\n",
        "\n",
        "}\n",
        "\n",
        "# Instantiate model\n",
        "xgb_model = XGBoostRegressorModel(\n",
        "    params={'verbosity':0},\n",
        "    num_boost_round=500,\n",
        "    early_stopping_rounds=20\n",
        ")\n",
        "\n",
        "# Run grid search on the validation split, optimizing RMSE\n",
        "best, all_results = xgb_model.grid_search(\n",
        "    df_XGB,\n",
        "    target_column='ActivePower_Mean',\n",
        "    param_grid=param_grid,\n",
        "    primary_metric='RMSE'   # or 'MAE', 'sMAPE', etc.\n",
        ")\n",
        "\n",
        "# Feed best parameters into run() for full train/val/test\n",
        "xgb_model.params.update(best['params'])\n",
        "final_results = xgb_model.run(df_XGB, target_column='ActivePower_Mean')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "51OnuM3c9jjX",
        "outputId": "1f6c30d0-1f96-449f-d204-f8930c91bdae"
      },
      "outputs": [],
      "source": [
        "# Grid Search Results\n",
        "\n",
        "rows = [\n",
        "    {**trial['params'], **trial['metrics']}\n",
        "    for trial in all_results\n",
        "]\n",
        "df_results = pd.DataFrame(rows)\n",
        "\n",
        "# 3) Sort by primary metric and display\n",
        "df_results = df_results.sort_values('RMSE').reset_index(drop=True)\n",
        "df_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_mAv8pmkmRM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Prepare data: numeric features only\n",
        "X = df_XGB.drop(columns=['ActivePower_Mean']).select_dtypes(include=[np.number])\n",
        "y = df_XGB['ActivePower_Mean'].values\n",
        "dtrain = xgb.DMatrix(X, label=y)\n",
        "\n",
        "# 1) Sweep reg_alpha with reg_lambda fixed\n",
        "alphas = np.logspace(-6, 0, 10)\n",
        "rmse_alpha = []\n",
        "for alpha in alphas:\n",
        "    params = {\n",
        "        'objective': 'reg:squarederror',\n",
        "        'eta': 0.2,\n",
        "        'max_depth': 5,\n",
        "        'subsample': 0.8,\n",
        "        'colsample_bytree': 0.7,\n",
        "        'reg_alpha': alpha,\n",
        "        'reg_lambda': 1.0,\n",
        "        'verbosity': 0\n",
        "    }\n",
        "    cv = xgb.cv(\n",
        "        params,\n",
        "        dtrain,\n",
        "        num_boost_round=500,\n",
        "        nfold=5,\n",
        "        metrics=('rmse',),\n",
        "        early_stopping_rounds=20,\n",
        "        as_pandas=True,\n",
        "        seed=42,\n",
        "        verbose_eval=False\n",
        "    )\n",
        "    rmse_alpha.append(cv['test-rmse-mean'].min())\n",
        "\n",
        "# 2) Sweep reg_lambda with reg_alpha fixed\n",
        "lambdas = np.logspace(-3, 2, 10)\n",
        "rmse_lambda = []\n",
        "for lam in lambdas:\n",
        "    params = {\n",
        "        'objective': 'reg:squarederror',\n",
        "        'eta': 0.2,\n",
        "        'max_depth': 5,\n",
        "        'subsample': 0.8,\n",
        "        'colsample_bytree': 0.7,\n",
        "        'reg_alpha': 1e-4,\n",
        "        'reg_lambda': lam,\n",
        "        'verbosity': 0\n",
        "    }\n",
        "    cv = xgb.cv(\n",
        "        params,\n",
        "        dtrain,\n",
        "        num_boost_round=500,\n",
        "        nfold=5,\n",
        "        metrics=('rmse',),\n",
        "        early_stopping_rounds=20,\n",
        "        as_pandas=True,\n",
        "        seed=42,\n",
        "        verbose_eval=False\n",
        "    )\n",
        "    rmse_lambda.append(cv['test-rmse-mean'].min())\n",
        "\n",
        "# 3) Plot results\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.semilogx(alphas, rmse_alpha, marker='o')\n",
        "plt.title('CV RMSE vs. reg_alpha')\n",
        "plt.xlabel('reg_alpha (L1 penalty)')\n",
        "plt.ylabel('Validation RMSE')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.semilogx(lambdas, rmse_lambda, marker='o')\n",
        "plt.title('CV RMSE vs. reg_lambda')\n",
        "plt.xlabel('reg_lambda (L2 penalty)')\n",
        "plt.ylabel('Validation RMSE')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
